name: Deploy PySpark ETL job

on:
  push:
    branches: [ "main", "dev" ]

env:
  AWS_REGION: "us-east-1"
  AWS_ACCOUNT_ID: "117819748843"


  


jobs:
  build:
    name: Build python package
    runs-on: ubuntu-latest
    container:
      image: public.ecr.aws/sam/build-python3.7:latest

    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Build python package
        run: |
          pip install venv-pack awscli build
          python -m build --sdist ./

      - uses: actions/upload-artifact@master
        with:
          name: python_package
          path: dist/

  test:
    needs: build
    name: test python package
    runs-on: ubuntu-latest
    container:
      image: public.ecr.aws/emr-serverless/spark/emr-6.10.0:latest

    steps:
      - uses: actions/download-artifact@master
        with:
          name: python_package
          path: dist/

      - name: Test python package
        run: |
          pip install pytest
          pip install ./dist/*
          python -m pytest

  deploy:
    needs: test
    name: Deploy python package
    runs-on: ubuntu-latest
    container:
      image: public.ecr.aws/sam/build-python3.7:latest

    if: github.ref == format('refs/heads/{0}', github.event.repository.default_branch)
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Push to ECR
        uses: vitr/actions-build-and-upload-to-ecs@master
        with:
          access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          account_id: ${{ env.AWS_ACCOUNT_ID }}
          repo: weather-etl/pyspark-env
          region: ${{ env.AWS_REGION }}
          tags: latest
          create_repo: false
         

      - name: Copy Python files to S3 deployment zone
        run: |
          aws s3 cp spark_entrypoint.py s3://deployment-zone-${AWS_ACCOUNT_ID}/weather_etl/
    

  deploy_sam:
    name: Deploy SAM template
    runs-on: ubuntu-latest
    environment: production
    container:
      image: public.ecr.aws/sam/build-python3.9:latest

    steps:
    - name: Checkout
      uses: actions/checkout@v3

    - name: SAM build
      run: sam build

    - name: SAM validate
      run: sam validate

    - name: Configure AWS credentials
      if: github.ref == format('refs/heads/{0}', github.event.repository.default_branch)
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
      
    - name: SAM deploy
      if: github.ref == format('refs/heads/{0}', github.event.repository.default_branch)
      run: sam deploy --no-fail-on-empty-changeset
